{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lab 1: Environments and Reproducibility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The software that you write for all of your research, whether it be data analysis or complex software should be FAIR: Findable, Accessible, Interoperable and Reusable. In short, the work you present in a paper should be reproducible with minimal effort by an external party. In order to facilitate this process, we will go through some techniques to reproduce your working environment. It begins with us actually creating an environment to begin with!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environments\n",
    "It is important for us to separate out projects managing various version of python and package dependencies, etc. There are a couple of popular package and environment managers: `conda`, `poetry`, `venv`, to name a few.\n",
    "\n",
    "We're going to keep things basic and use `venv`. Creating virtual environments is really easy. You would usually first create a directory and navigate to that directory. In macos or linux:\n",
    "\n",
    "```bash\n",
    "$ mkdir ProjectName\n",
    "$ cd ProjectName\n",
    "```\n",
    "\n",
    "In Windows it's the same. But we already have a folder to work in. So navigate to the AutumnSchool folder using the command line. To make the virtual environment:\n",
    "\n",
    "```bash\n",
    "$ python -m venv venv # the second venv is the name of the environment. You can call this anything.\n",
    "```\n",
    "\n",
    "and again it should be the same in Windows.\n",
    "\n",
    "To activate the `venv`\n",
    "\n",
    "```bash\n",
    "$ source venv/bin/activate\n",
    "```\n",
    "\n",
    "and in Windows command line:\n",
    "\n",
    "```bash\n",
    "C:\\> venv\\Scripts\\activate.bat\n",
    "```\n",
    "\n",
    "or in Powershell:\n",
    "\n",
    "```bash\n",
    "PS C:\\> venv\\Scripts\\Activate.ps1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to open VSCode. From where you are in the terminal, run\n",
    "\n",
    "```bash\n",
    "$ code . # there is a fullstop here...\n",
    "```\n",
    "\n",
    "And this should open VSCode in the current directory. If you want to keep using the existing terminal, that's fine. But it's convenient to use the terminal at the bottom of the screen. Hit `cmd` + `~` to open the terminal if it isn't already open. You can now run the following:\n",
    "\n",
    "```bash\n",
    "$ python -m pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "This should install all of the stuff we need for the course. It is generally a good idea to add packages to your `requirements.txt` file as you go. You can run\n",
    "\n",
    "```bash\n",
    "$ pip freeze\n",
    "```\n",
    "\n",
    "to see a list of python packages installed, and you can also dump the installed packages using\n",
    "\n",
    "```bash\n",
    "$ pip freeze > requirements.txt\n",
    "```\n",
    "\n",
    "Package managers like `conda` and Poetry can automatically generate files that recreate your environment for you, typically in the form of a `.toml` file. We'll talk about this later..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A note on Anaconda, `conda` and IDEs\n",
    "\n",
    "Anaconda has dual functionality: it will help manage your packages and will also manage your virtual environments. It is a very powerful tool, especially if collaborating with others. It also comes with `conda`, a command line tool, which is also available independent of anaconda.\n",
    "\n",
    "Why are we using VSCode? Because it's great. It's lightweight, supports every language under the sun, has a plugin for practically everything, and you can make choose from loads of fancy themes!\n",
    "\n",
    "Spyder and PyCharm are also very powerful IDEs. One feature of PyCharm is that it will create separate anaconda environments for your projects, which can sometimes take up space.\n",
    "\n",
    "For this course, we will be using VSCode. You're welcome to use any other IDE or editor (like VIM or Nano, if you're insane), but you're on your own in terms of support."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reproducibility\n",
    "\n",
    "There might be occasions where you need random number generation. For example:\n",
    "- Drawing from probability distributions for simulations\n",
    "- Initializing the weights in a neural network\n",
    "- Shuffling training data\n",
    "\n",
    "Although we call this \"random\", it isn't of course. True randomness is very difficult to generate at the scale of computer hardware. Instead we use pseudo-random number generation.\n",
    "\n",
    "In your programs, there might be a few sources of randomness that you want to control in order to ensure reproducibility. The first of these is the python random number generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6177528569514706\n",
      "0.5332655736050008\n",
      "Reinitializing the random number generator\n",
      "0.6177528569514706\n",
      "0.5332655736050008\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "random.seed(1337)\n",
    "print(random.random())\n",
    "print(random.random())\n",
    "print(\"Reinitializing the random number generator...\")\n",
    "random.seed(1337)\n",
    "print(random.random())\n",
    "print(random.random())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next one is the numpy random number generator. It is common to set the seed using\n",
    "\n",
    "```python\n",
    "np.random.seed(1337)\n",
    "```\n",
    "\n",
    "but the best practice is to use a `Generator` instance instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8781019003471183\n",
      "0.18552796163759344\n",
      "Reinitializing the random number generator...\n",
      "0.8781019003471183\n",
      "0.18552796163759344\n"
     ]
    }
   ],
   "source": [
    "from numpy.random import default_rng\n",
    "\n",
    "rng = default_rng(1337)\n",
    "print(rng.random())\n",
    "print(rng.random())\n",
    "print(\"Reinitializing the random number generator...\")\n",
    "rng = default_rng(1337)\n",
    "print(rng.random())\n",
    "print(rng.random())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The advantages of this is that you can use the random number generator for specific purposes while avoiding any other imported packaged from resetting your global random seed. For most uses, however, using the global method will be OK.\n",
    "\n",
    "Next up, we have sources of randomness from Scikit-Learn. Let's have a look at this..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.random.mtrand.RandomState"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import check_random_state\n",
    "type(check_random_state(None))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we have seen that sklearn just uses the global numpy seed. But let's quickly verify this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.36765581 -0.52731021 -0.34277954 -0.06888807  3.23657406]\n",
      " [ 0.02841567 -0.3677821   0.73551962  0.75131746 -4.07905129]\n",
      " [-0.17569734  0.19852565 -0.57926018  1.6052553   1.35179923]\n",
      " [ 0.44734809  0.45439334 -0.2143415  -1.1645211   2.64666125]\n",
      " [ 0.40194782 -0.48231493 -0.32726745  0.4198575   3.73596932]]\n",
      "[[-0.36765581 -0.52731021 -0.34277954 -0.06888807  3.23657406]\n",
      " [ 0.02841567 -0.3677821   0.73551962  0.75131746 -4.07905129]\n",
      " [-0.17569734  0.19852565 -0.57926018  1.6052553   1.35179923]\n",
      " [ 0.44734809  0.45439334 -0.2143415  -1.1645211   2.64666125]\n",
      " [ 0.40194782 -0.48231493 -0.32726745  0.4198575   3.73596932]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy as np\n",
    "\n",
    "X = np.random.rand(5,5)\n",
    "y = np.random.randint(0,5, (5,))\n",
    "\n",
    "np.random.seed(1337)\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(5, 5), random_state=None)\n",
    "clf.fit(X, y)\n",
    "print(clf.coefs_[0])\n",
    "\n",
    "np.random.seed(1337)\n",
    "clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                    hidden_layer_sizes=(5, 5), random_state=None)\n",
    "clf.fit(X, y)\n",
    "print(clf.coefs_[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's super annyoying having to reset the random seed if you want to reproduce results, so we'll have a look at this later. But first, let's tackle PyTorch. There is a lot of nondeterministic features of PyTorch. You can use the torch `manual_seed()` method to fix the RNG:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x135438ad0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.manual_seed(1337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Annoyingly, PyTorch operations can sometimes use internal random number generators, so if the operation is called over and over, you'll get different results unless you set the manual seed between calls, like we did with sklearn.\n",
    "\n",
    "In addition, the cuDNN library also can be a source of nondeterminism. This is to do with how cuDNN finds optimal convolution algorithms. You can disable this by using\n",
    "\n",
    "```python\n",
    "torch.backends.cudnn.benchmarks = False\n",
    "```\n",
    "\n",
    "You can also avoid nondeterministic algorithms, by using\n",
    "\n",
    "```python\n",
    "torch.use_deterministic_algorithms()\n",
    "```\n",
    "\n",
    "This will mess with a lot of potential neural network layers like LSTM and max pooling layers, and probably should be avoided.\n",
    "\n",
    "The short version of the story is it is almost impossible to guarantee absolute reproducibility across all PyTorch versions, on multiple platforms. **In general you should not assume perfect reproducibility between CPU and GPU executions**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reproducibility from MATLAB to NumPy\n",
    "This is something that might be important to you when verifying algorthims that you are translating from MATLAB to NumPy, and is something that has personally caused me quite a bit of grief.\n",
    "\n",
    "It is possible to exactly reproduce a significant amount of randomness between MATLAB and NumPy. NumPy uses the Mersenne Twister 19937 algorthim by default, and you can force MATLAB to use the same algorithm. This means that both languages will produce the same string of random numbers.\n",
    "\n",
    "Since MATLAB and NumPy also both use the same underlying linear algebra subroutines (BLAS and LAPACK, both written in FORTRAN), you can also reproduce the results of many common linear solvers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**WARNING**: You should not use these random number generators for security or cryptographic purposes. There are other libraries that exist for this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've discussed randomness and reproducibility a little, let's see how we can set these things globally."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "DEFAULT_SEED = 1337\n",
    "\n",
    "def set_python(seed=DEFAULT_SEED):\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    random.seed(seed)\n",
    "\n",
    "def set_numpy(seed=DEFAULT_SEED):\n",
    "    np.random.seed(seed)\n",
    "\n",
    "def set_torch(seed=DEFAULT_SEED, deterministic=False):\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    if deterministic:\n",
    "        torch.backends.cudnn.benchmark = False\n",
    "        torch.backends.cudnn.deterministic = True\n",
    "\n",
    "def set_all_seeds(seed=DEFAULT_SEED, deterministic=False):\n",
    "    set_python(seed)\n",
    "    set_numpy(seed)\n",
    "    set_torch(seed, deterministic)\n",
    "\n",
    "set_all_seeds(1337)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do not optimize for random seed! Do not base any decisions you make on your random seed!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
